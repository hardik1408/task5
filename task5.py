# -*- coding: utf-8 -*-
"""task5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aVPlAp9rOA4eh-WBz5qFG7SXaqcGim5X
"""

import numpy as np
import pandas as pd

!pip install py7zr

from py7zr import unpack_7zarchive
import shutil
shutil.register_unpack_format('7zip',['.7z'],unpack_7zarchive)
shutil.unpack_archive('train.7z', 'temp')

train_labels = pd.read_csv("trainLabels.csv", header="infer")

classes = train_labels['label'].unique()
print(classes)

from sklearn.metrics import confusion_matrix, classification_report
import itertools
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import Dense, Dropout, Activation,Flatten,Conv2D,MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.datasets import cifar10

model=Sequential()
model.add( Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False, input_shape=(32,32,3)) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=48, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=80, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=112, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=144, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=160, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add( Conv2D(filters=176, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Flatten())

model.add(Dense(units=10))
model.add(BatchNormalization())
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

train_datagen = ImageDataGenerator(featurewise_center=False,
                             samplewise_center=False,
                             featurewise_std_normalization=False,
                             samplewise_std_normalization=False,
                             zca_whitening=False,
                             rotation_range=10,
                             zoom_range=0.1,
                             width_shift_range=0.1,
                             height_shift_range=0.1,
                             horizontal_flip=False,
                             vertical_flip=False,
                             rescale=1./255)
valid_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(directory='/temp/train/', shuffle=True, target_size=(32,32),batch_size=128)
valid_generator = valid_datagen.flow_from_directory(directory='/temp/valid/', shuffle=True, target_size=(32,32),batch_size=128)

model.fit(train_generator,epochs=50, validation_data=valid_generator,steps_per_epoch=train_generator.n//train_generator.batch_size,
         validation_steps= valid_generator.n//valid_generator.batch_size,workers=8,use_multiprocessing=True)